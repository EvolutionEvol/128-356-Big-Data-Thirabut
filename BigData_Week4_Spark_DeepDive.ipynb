{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell_0",
   "metadata": {},
   "source": [
    "# üìò Big Data ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå‡∏ó‡∏µ‡πà 4: Distributed Processing & Apache Spark (Deep Dive)\n",
    "\n",
    "**‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤:** ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà (Big Data) ‚Äî 128-356  \n",
    "**‡∏Ñ‡∏ì‡∏∞:** ‡∏Ñ‡∏ì‡∏∞‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå ‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡∏™‡∏¢‡∏≤‡∏°  \n",
    "**‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå‡∏ó‡∏µ‡πà:** 4  \n",
    "\n",
    "> üéØ **‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ:** ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î Distributed Computing, ‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡∏Ç‡∏≠‡∏á Apache Spark, Lazy Evaluation, DAG ‡πÅ‡∏•‡∏∞ Shuffle ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏•‡∏á‡∏°‡∏∑‡∏≠‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏à‡∏£‡∏¥‡∏á‡∏î‡πâ‡∏ß‡∏¢ PySpark\n",
    "\n",
    "**‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á**: Google Colab (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥) / Local Jupyter  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell_1",
   "metadata": {},
   "source": [
    "# 1. üñ•Ô∏è ‡∏ó‡∏≥‡πÑ‡∏°‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ñ‡∏∂‡∏á‡πÑ‡∏°‡πà‡∏û‡∏≠? (Why Single Machine Fails)\n",
    "\n",
    "## ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß\n",
    "\n",
    "‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏∂‡πâ‡∏ô ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏´‡∏•‡∏≤‡∏¢‡∏î‡πâ‡∏≤‡∏ô:\n",
    "\n",
    "| ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤ |\n",
    "|----------|----------|---------------|\n",
    "| **RAM** | ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏°‡∏µ‡∏à‡∏≥‡∏Å‡∏±‡∏î (‡πÄ‡∏ä‡πà‡∏ô 16 GB) | ‡∏•‡∏≠‡∏á‡πÇ‡∏´‡∏•‡∏î CSV 50 GB ‡∏î‡πâ‡∏ß‡∏¢ Pandas ‚Üí MemoryError |\n",
    "| **CPU** | ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Core ‡∏°‡∏µ‡∏à‡∏≥‡∏Å‡∏±‡∏î (‡πÄ‡∏ä‡πà‡∏ô 4-8 Cores) | ‡∏á‡∏≤‡∏ô groupBy ‡∏ö‡∏ô 1 ‡∏û‡∏±‡∏ô‡∏•‡πâ‡∏≤‡∏ô‡πÅ‡∏ñ‡∏ß ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡∏•‡∏≤‡∏¢‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á |\n",
    "| **I/O** | Disk ‡∏≠‡πà‡∏≤‡∏ô/‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ä‡πâ‡∏≤ | ‡∏™‡πÅ‡∏Å‡∏ô‡πÑ‡∏ü‡∏•‡πå 100 GB ‡∏à‡∏≤‡∏Å HDD ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤ ~15 ‡∏ô‡∏≤‡∏ó‡∏µ |\n",
    "| **‡πÑ‡∏°‡πà‡∏Ç‡∏¢‡∏≤‡∏¢‡πÑ‡∏î‡πâ** | ‡πÄ‡∏û‡∏¥‡πà‡∏° RAM/CPU ‡∏°‡∏µ‡πÄ‡∏û‡∏î‡∏≤‡∏ô | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÅ‡∏û‡∏á‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏ï‡∏•‡∏≤‡∏î‡∏Å‡πá‡∏°‡∏µ‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î |\n",
    "\n",
    "### üí° ‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (Key Insight)\n",
    "\n",
    "> ‡πÄ‡∏°‡∏∑‡πà‡∏≠ **‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• √ó ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô > ‡∏Ç‡∏µ‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß**  \n",
    "> ‚Üí ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ **Distributed Computing** (‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢)\n",
    "\n",
    "### ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢ ‡πÜ\n",
    "\n",
    "- **‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß** = ‡∏Ñ‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏¢‡∏Å‡∏≠‡∏¥‡∏ê 10,000 ‡∏Å‡πâ‡∏≠‡∏ô ‚Üí ‡πÄ‡∏´‡∏ô‡∏∑‡πà‡∏≠‡∏¢ ‡∏ä‡πâ‡∏≤ ‡πÄ‡∏™‡∏µ‡∏¢‡πÄ‡∏ß‡∏•‡∏≤\n",
    "- **Distributed** = ‡∏Ñ‡∏ô 100 ‡∏Ñ‡∏ô ‡∏ä‡πà‡∏ß‡∏¢‡∏Å‡∏±‡∏ô‡∏¢‡∏Å‡∏Ñ‡∏ô‡∏•‡∏∞ 100 ‡∏Å‡πâ‡∏≠‡∏ô ‚Üí ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÄ‡∏£‡πá‡∏ß!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"images/single_vs_distributed.png\" width=\"800\" alt=\"Single Machine vs Distributed Computing: ‡∏Ñ‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÅ‡∏ö‡∏Å‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡∏±‡∏Å vs ‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡∏Å‡∏±‡∏ô‡πÅ‡∏ö‡∏Å\">\n",
    "  <br><i>Single Machine vs Distributed Computing: ‡∏Ñ‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÅ‡∏ö‡∏Å‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡∏±‡∏Å vs ‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡∏Å‡∏±‡∏ô‡πÅ‡∏ö‡∏Å</i>\n",
    "</div>\n"
   ],
   "id": "img_single_vs_distributed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell_2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡∏•‡∏≠‡∏á‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß\n",
    "import psutil, os\n",
    "\n",
    "ram_gb = psutil.virtual_memory().total / (1024**3)\n",
    "cpu_count = os.cpu_count()\n",
    "\n",
    "print(f\"üñ•Ô∏è ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ô‡∏µ‡πâ‡∏°‡∏µ RAM: {ram_gb:.1f} GB\")\n",
    "print(f\"üîß ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô CPU Cores: {cpu_count}\")\n",
    "print(f\"\\nüí° ‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏ç‡πà‡∏Å‡∏ß‡πà‡∏≤ {ram_gb:.0f} GB ‚Üí Pandas ‡∏à‡∏∞ crash!\")\n",
    "print(f\"üí° ‡∏ñ‡πâ‡∏≤ query ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡πÅ‡∏Ñ‡πà {cpu_count} cores ‚Üí ‡∏ä‡πâ‡∏≤!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell_3",
   "metadata": {},
   "source": [
    "### ‚úèÔ∏è ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏ó‡∏µ‡πà 1: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î\n",
    "\n",
    "**‡πÇ‡∏à‡∏ó‡∏¢‡πå:** ‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Log 500 GB/‡∏ß‡∏±‡∏ô ‡∏ï‡πâ‡∏≠‡∏á JOIN ‡∏Å‡∏±‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á 50 GB ‡πÅ‡∏•‡∏∞ GROUP BY  \n",
    "‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á Server ‡∏°‡∏µ RAM 64 GB, 16 Cores\n",
    "\n",
    "**‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°** (‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÉ‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell_4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏ó‡∏µ‡πà 1: ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö\n",
    "\n",
    "# 1) ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Å‡∏µ‡πà GB?\n",
    "total_data_gb = ________  # ‡πÄ‡∏ï‡∏¥‡∏°‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç\n",
    "\n",
    "# 2) RAM ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà? (True/False)\n",
    "ram_enough = ________  # True ‡∏´‡∏£‡∏∑‡∏≠ False\n",
    "\n",
    "# 3) ‡∏ñ‡πâ‡∏≤‡∏≠‡πà‡∏≤‡∏ô disk ‡πÑ‡∏î‡πâ 200 MB/s ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏≤‡∏ô‡∏Å‡∏µ‡πà‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ (‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì)?\n",
    "read_time_sec = ________  # ‡πÄ‡∏ï‡∏¥‡∏°‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç\n",
    "\n",
    "# 4) ‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ Distributed Computing ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà? ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏≠‡∏∞‡πÑ‡∏£?\n",
    "answer = \"________\"\n",
    "\n",
    "print(f\"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏ß‡∏°: {total_data_gb} GB\")\n",
    "print(f\"RAM ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠: {ram_enough}\")\n",
    "print(f\"‡πÄ‡∏ß‡∏•‡∏≤‡∏≠‡πà‡∏≤‡∏ô disk: {read_time_sec} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‚âà {read_time_sec/60:.1f} ‡∏ô‡∏≤‡∏ó‡∏µ\")\n",
    "print(f\"‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: {answer}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell_5",
   "metadata": {},
   "source": [
    "# 2. üî• Apache Spark ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?\n",
    "\n",
    "## ‡∏ô‡∏¥‡∏¢‡∏≤‡∏°\n",
    "\n",
    "Apache Spark ‡∏Ñ‡∏∑‡∏≠ **Distributed Computing Engine** (‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏¢‡∏ô‡∏ï‡πå‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà\n",
    "\n",
    "> Spark ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô \"‡∏™‡∏°‡∏≠‡∏á‡∏Å‡∏•‡∏≤‡∏á\" ‡∏ó‡∏µ‡πà‡∏™‡∏±‡πà‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏•‡∏≤‡∏¢‡∏£‡πâ‡∏≠‡∏¢‡∏ï‡∏±‡∏ß‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô\n",
    "\n",
    "## ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏´‡∏•‡∏±‡∏Å\n",
    "\n",
    "| ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥ | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ | ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö |\n",
    "|-----------|----------|-------------|\n",
    "| **In-Memory Processing** | ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÉ‡∏ô RAM ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô disk ‡∏ó‡∏∏‡∏Å‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô | ‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤ Hadoop MapReduce 10-100 ‡πÄ‡∏ó‡πà‡∏≤ |\n",
    "| **DAG Execution** | ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏á‡∏≤‡∏ô‡πÄ‡∏õ‡πá‡∏ô Graph ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏≥‡∏à‡∏£‡∏¥‡∏á | ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡πâ‡∏≤‡∏ô |\n",
    "| **Fault Tolerance** | ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏û‡∏±‡∏á ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏î‡πâ | ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏°‡∏µ‡∏™‡∏≥‡πÄ‡∏ô‡∏≤‡∏™‡∏π‡∏ï‡∏£‡∏≠‡∏≤‡∏´‡∏≤‡∏£ |\n",
    "| **Unified Engine** | ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö SQL, ML, Streaming, Graph | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏¢‡∏≠‡∏¢‡πà‡∏≤‡∏á |\n",
    "\n",
    "## ‚ö†Ô∏è Spark ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏≠‡∏∞‡πÑ‡∏£?\n",
    "\n",
    "- ‚ùå **‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà Database** ‚Äî Spark ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡∏≤‡∏ß‡∏£\n",
    "- ‚ùå **‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà Storage System** ‚Äî Spark ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å HDFS, S3, Parquet ‡∏Ø‡∏•‡∏Ø\n",
    "- ‚úÖ **Spark = Compute Layer** ‚Äî ‡πÄ‡∏õ‡πá‡∏ô \"‡∏ä‡∏±‡πâ‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•\" ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏±‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "\n",
    "### ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Spark ‡∏Å‡∏±‡∏ö‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏≠‡∏∑‡πà‡∏ô\n",
    "\n",
    "| ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠ | ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö | ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• | ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß |\n",
    "|-----------|---------|-----------|---------|\n",
    "| **Pandas** | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß, EDA | MB - ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô RAM | ‡πÄ‡∏£‡πá‡∏ß (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏•‡πá‡∏Å) |\n",
    "| **DuckDB** | SQL Analytics ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß | MB - GB | ‡πÄ‡∏£‡πá‡∏ß‡∏°‡∏≤‡∏Å |\n",
    "| **Spark** | Distributed, Data Pipeline | GB - PB | ‡πÄ‡∏£‡πá‡∏ß (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏ç‡πà) |\n",
    "| **Hadoop MR** | Batch ‡∏ö‡∏ô HDFS | TB - PB | ‡∏ä‡πâ‡∏≤ (‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô disk ‡∏ó‡∏∏‡∏Å‡∏Ç‡∏±‡πâ‡∏ô) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell_6",
   "metadata": {},
   "source": [
    "# 3. üèóÔ∏è ‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏° Spark ‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å (Spark Architecture Deep Dive)\n",
    "\n",
    "## ‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏´‡∏•‡∏±‡∏Å 3 ‡∏™‡πà‡∏ß‡∏ô\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ         Cluster Manager             ‚îÇ\n",
    "‚îÇ    (‡∏ú‡∏π‡πâ‡∏à‡∏±‡∏î‡∏™‡∏£‡∏£‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£: YARN/K8s)     ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "           ‚îÇ ‡∏à‡∏±‡∏î‡∏™‡∏£‡∏£ CPU/RAM\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚ñº             ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ Driver ‚îÇ‚îÄ‚îÄ‚ñ∂‚îÇ   Executors (N ‡∏ï‡∏±‡∏ß) ‚îÇ\n",
    "‚îÇ (‡∏™‡∏°‡∏≠‡∏á) ‚îÇ   ‚îÇ   (‡πÅ‡∏£‡∏á‡∏á‡∏≤‡∏ô)         ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### üß† Driver (‡∏™‡∏°‡∏≠‡∏á) ‚Äî ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà:\n",
    "1. **‡∏™‡∏£‡πâ‡∏≤‡∏á SparkSession** ‚Äî ‡πÄ‡∏õ‡∏¥‡∏î‡∏õ‡∏£‡∏∞‡∏ï‡∏π‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà Spark\n",
    "2. **‡∏™‡∏£‡πâ‡∏≤‡∏á Logical Plan** ‚Äî ‡πÅ‡∏õ‡∏•‡∏á‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ú‡∏ô‡∏á‡∏≤‡∏ô\n",
    "3. **Optimize** ‚Äî ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ú‡∏ô‡πÉ‡∏´‡πâ‡πÄ‡∏£‡πá‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡∏ú‡πà‡∏≤‡∏ô Catalyst Optimizer)\n",
    "4. **‡πÅ‡∏ö‡πà‡∏á‡∏á‡∏≤‡∏ô** ‚Äî ‡πÅ‡∏ö‡πà‡∏á Job ‚Üí Stages ‚Üí Tasks\n",
    "5. **‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏ú‡∏•** ‚Äî ‡∏î‡∏π‡∏ß‡πà‡∏≤ Executor ‡∏ó‡∏≥‡πÄ‡∏™‡∏£‡πá‡∏à‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á\n",
    "\n",
    "### ‚öôÔ∏è Executor (‡πÅ‡∏£‡∏á‡∏á‡∏≤‡∏ô) ‚Äî ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà:\n",
    "1. **‡∏£‡∏±‡∏ö Task ‡∏°‡∏≤‡∏ó‡∏≥** ‚Äî ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á ‡πÜ\n",
    "2. **‡πÄ‡∏Å‡πá‡∏ö Cache** ‚Äî ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô RAM ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏ã‡πâ‡∏≥\n",
    "3. **Shuffle** ‚Äî ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
    "4. **‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ú‡∏•** ‚Äî ‡∏™‡πà‡∏á‡∏ú‡∏•‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏ó‡∏µ‡πà Driver\n",
    "\n",
    "### üîÑ ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô: Job ‚Üí Stage ‚Üí Task ‚Üí Partition\n",
    "\n",
    "| ‡∏£‡∏∞‡∏î‡∏±‡∏ö | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ | ‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å |\n",
    "|------|----------|--------|\n",
    "| **Job** | ‡∏á‡∏≤‡∏ô‡πÉ‡∏´‡∏ç‡πà 1 ‡∏ä‡∏¥‡πâ‡∏ô | ‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å Action (‡πÄ‡∏ä‡πà‡∏ô `.count()`) |\n",
    "| **Stage** | ‡∏ä‡πà‡∏ß‡∏á‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á Shuffle | ‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏à‡∏∏‡∏î Shuffle |\n",
    "| **Task** | ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô‡∏¢‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î | 1 Task ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• 1 Partition |\n",
    "| **Partition** | ‡∏ä‡∏¥‡πâ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• | ‡πÑ‡∏ü‡∏•‡πå‡∏ñ‡∏π‡∏Å‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô Partition ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ |\n",
    "\n",
    "> üí° **‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö:** Job = ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡πâ‡∏≤‡∏ô, Stage = ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô (‡πÄ‡∏ó‡∏ê‡∏≤‡∏ô/‡∏Å‡πà‡∏≠‡∏ú‡∏ô‡∏±‡∏á/‡∏°‡∏∏‡∏á‡∏´‡∏•‡∏±‡∏á‡∏Ñ‡∏≤), Task = ‡∏ä‡πà‡∏≤‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏ô, Partition = ‡∏ß‡∏±‡∏™‡∏î‡∏∏‡∏ó‡∏µ‡πà‡πÅ‡∏ö‡πà‡∏á‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏≤‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏ô\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"images/driver_internal.png\" width=\"800\" alt=\"Driver Internals Diagram\">\n",
    "  <br><i>‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏Ç‡∏≠‡∏á Driver: SparkSession, DAGScheduler, TaskScheduler</i>\n",
    "</div>\n",
    "\n",
    "#### üß† ‡πÄ‡∏à‡∏≤‡∏∞‡∏•‡∏∂‡∏Å Driver Internals\n",
    "- **SparkSession**: ‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î (Entry Point)\n",
    "- **DAGScheduler**: ‡πÅ‡∏õ‡∏•‡∏á Logical Plan ‡πÄ‡∏õ‡πá‡∏ô Physical Plan ‡πÅ‡∏•‡∏∞‡πÅ‡∏ö‡πà‡∏á‡∏á‡∏≤‡∏ô‡πÄ‡∏õ‡πá‡∏ô Stages (Stage 1, Stage 2)\n",
    "- **TaskScheduler**: ‡∏£‡∏±‡∏ö Stage ‡∏°‡∏≤‡πÅ‡∏ï‡∏Å‡πÄ‡∏õ‡πá‡∏ô Task ‡∏¢‡πà‡∏≠‡∏¢‡πÜ ‡πÅ‡∏•‡πâ‡∏ß‡∏™‡πà‡∏á‡πÑ‡∏õ‡πÉ‡∏´‡πâ Executor ‡∏ó‡∏µ‡πà‡∏ß‡πà‡∏≤‡∏á‡∏≠‡∏¢‡∏π‡πà\n",
    "- **SchedulerBackend**: ‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏Å‡∏±‡∏ö Cluster Manager ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£ (CPU/RAM)\n"
   ],
   "id": "added_md_89bd6e99"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"images/spark_chef_analogy.png\" width=\"800\" alt=\"Spark Architecture Analogy: Driver (Chef) ‡∏™‡∏±‡πà‡∏á‡∏á‡∏≤‡∏ô Executors (Cooks)\">\n",
    "  <br><i>Spark Architecture Analogy: Driver (Chef) ‡∏™‡∏±‡πà‡∏á‡∏á‡∏≤‡∏ô Executors (Cooks)</i>\n",
    "</div>\n"
   ],
   "id": "img_spark_chef_analogy"
  },
  {
   "cell_type": "markdown",
   "id": "cell_7",
   "metadata": {},
   "source": [
    "### 3.1 üß† Deep Dive: SparkSession vs SparkContext\n",
    "\n",
    "‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏ô‡∏≠‡∏≤‡∏à‡∏™‡∏á‡∏™‡∏±‡∏¢‡∏ß‡πà‡∏≤ `SparkSession` ‡∏Å‡∏±‡∏ö `SparkContext` ‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?\n",
    "\n",
    "#### 1. SparkContext (`sc`) ‚Äî The Engine üîß\n",
    "- ‡πÄ‡∏õ‡πá‡∏ô **Entry Point** ‡∏î‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏¥‡∏°‡∏Ç‡∏≠‡∏á Spark (‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô 1.x)\n",
    "- ‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Cluster Manager (YARN, K8s, Standalone)\n",
    "- ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Executors, Memory, ‡πÅ‡∏•‡∏∞ Job Scheduling\n",
    "- **‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö:** ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô **\"‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏¢‡∏ô‡∏ï‡πå\"** ‡∏Ç‡∏≠‡∏á‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå ‚Äî ‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ç‡∏±‡∏ö‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Å‡∏•‡πÑ‡∏Å‡∏†‡∏≤‡∏¢‡πÉ‡∏ô\n",
    "\n",
    "#### 2. SparkSession (`spark`) ‚Äî The Dashboard üöó\n",
    "- ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏ä‡πâ‡πÉ‡∏ô Spark 2.0+\n",
    "- ‡πÄ‡∏õ‡πá‡∏ô **Unified Entry Point** ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏î‡∏µ‡∏¢‡∏ß:\n",
    "  - `SparkContext` (Core)\n",
    "  - `SQLContext` (DataFrames/SQL)\n",
    "  - `HiveContext` (Hive tables)\n",
    "  - `StreamingContext` (Streaming)\n",
    "- **‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö:** ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô **\"‡∏Ñ‡∏ô‡∏Ç‡∏±‡∏ö\"** ‡∏´‡∏£‡∏∑‡∏≠ **\"‡πÅ‡∏ú‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏õ‡∏±‡∏î\"** ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á (‡πÄ‡∏£‡∏≤‡∏Ç‡∏±‡∏ö‡∏£‡∏ñ‡∏ú‡πà‡∏≤‡∏ô‡∏û‡∏ß‡∏á‡∏°‡∏≤‡∏•‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÑ‡∏õ‡∏´‡∏°‡∏∏‡∏ô‡∏•‡πâ‡∏≠‡πÄ‡∏≠‡∏á)\n",
    "\n",
    "> üí° **Best Practice:** ‡πÉ‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô **‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ `SparkSession` ‡πÄ‡∏™‡∏°‡∏≠** (‡πÅ‡∏ï‡πà‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á‡∏°‡∏±‡∏ô‡∏Å‡πá‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ `SparkContext` ‡∏≠‡∏¢‡∏π‡πà‡∏î‡∏µ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell_8",
   "metadata": {},
   "source": [
    "## üî¨ Lab: ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Spark\n",
    "\n",
    "### Step 1: ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell_9",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á PySpark (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Colab)\n",
    "!pip -q install pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á SparkSession ‚Äî ‡∏õ‡∏£‡∏∞‡∏ï‡∏π‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà Spark\n",
    "# üí° config(\"spark.ui.port\", \"4050\") ‡∏Å‡∏≥‡∏´‡∏ô‡∏î port ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á port 4040 ‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏ä‡∏ô‡∏Å‡∏±‡∏ô\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BigData-Week4-DeepDive\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.ui.port\", \"4050\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á SparkContext ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å wrap ‡∏≠‡∏¢‡∏π‡πà‡∏Ç‡πâ‡∏≤‡∏á‡πÉ‡∏ô\n",
    "sc = spark.sparkContext\n",
    "\n",
    "print(f\"‚úÖ Spark Version: {spark.version}\")\n",
    "print(f\"üì± App Name: {sc.appName}\")\n",
    "print(f\"üñ•Ô∏è Master: {sc.master}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell_10",
   "metadata": {},
   "source": [
    "### 3.2 üõ†Ô∏è ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: ‡πÄ‡∏õ‡∏¥‡∏î Spark UI ‡πÉ‡∏ô Google Colab\n",
    "\n",
    "**‡∏õ‡∏±‡∏ç‡∏´‡∏≤:** ‡∏õ‡∏Å‡∏ï‡∏¥ Spark UI ‡∏à‡∏∞‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà `localhost:4040` ‡πÅ‡∏ï‡πà Google Colab ‡∏£‡∏±‡∏ô‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á Server (Virtual Machine) ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á `localhost` ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á\n",
    "\n",
    "**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:** ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ library `google.colab.output` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á Proxy ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏î‡πâ\n",
    "\n",
    "‡∏£‡∏±‡∏ô cell ‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏¥‡∏î Spark UI üëá\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell_11",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üõ†Ô∏è Code ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡∏¥‡∏î Spark UI ‡πÉ‡∏ô Colab\n",
    "try:\n",
    "    from google.colab import output\n",
    "    \n",
    "    # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡∏¥‡∏î Spark UI\n",
    "    def show_spark_ui(port=4050):\n",
    "        # ‡∏î‡∏∂‡∏á URL ‡∏Ç‡∏≠‡∏á Spark UI ‡∏ú‡πà‡∏≤‡∏ô Proxy ‡∏Ç‡∏≠‡∏á Colab\n",
    "        url = output.serve_kernel_port_as_iframe(port)\n",
    "        # ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏õ‡πá‡∏ô Link ‡πÉ‡∏´‡πâ‡∏Ñ‡∏•‡∏¥‡∏Å (‡∏ñ‡πâ‡∏≤ iframe ‡πÄ‡∏•‡πá‡∏Å‡πÑ‡∏õ)\n",
    "        # output.serve_kernel_port_as_window(port)\n",
    "        print(f\"üöÄ Spark UI ‡πÄ‡∏õ‡∏¥‡∏î‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà: {url}\")\n",
    "        print(\"üí° ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏´‡πá‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏Ñ‡∏•‡∏¥‡∏Å link ‡∏ô‡∏µ‡πâ‡πÅ‡∏ó‡∏ô (‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á login Google):\")\n",
    "        output.serve_kernel_port_as_window(port, path='/jobs/')\n",
    "\n",
    "    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (Default port ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏ß‡πâ‡∏Ñ‡∏∑‡∏≠ 4050)\n",
    "    show_spark_ui(4050)\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ô‡∏ö‡∏ô Google Colab ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏û‡∏ö library google.colab\")\n",
    "    print(f\"üëâ ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏£‡∏±‡∏ô‡∏ö‡∏ô Local Jupyter ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡∏¥‡∏î: http://localhost:4050\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell_12",
   "metadata": {},
   "source": [
    "# 4. üè¢ Cluster Managers (‡∏ú‡∏π‡πâ‡∏à‡∏±‡∏î‡∏™‡∏£‡∏£‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£)\n",
    "\n",
    "Cluster Manager ‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡∏™‡∏£‡∏£ CPU ‡πÅ‡∏•‡∏∞ RAM ‡πÉ‡∏´‡πâ Spark ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÑ‡∏î‡πâ‡∏Å‡∏±‡∏ö \"‡∏ú‡∏π‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£\" ‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡∏´‡πâ‡∏≠‡∏á‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡πà‡∏≤\n",
    "\n",
    "## ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Cluster Manager 3 ‡πÅ‡∏ö‡∏ö\n",
    "\n",
    "| | **Standalone** | **YARN** | **Kubernetes** |\n",
    "|---|---|---|---|\n",
    "| **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢** | Cluster Manager ‡∏Ç‡∏≠‡∏á Spark ‡πÄ‡∏≠‡∏á | Hadoop ecosystem | Container-based |\n",
    "| **‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á** | ‡∏á‡πà‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î | ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ Hadoop | ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ K8s cluster |\n",
    "| **‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö** | ‡∏ó‡∏î‡∏•‡∏≠‡∏á, ‡∏ó‡∏µ‡∏°‡πÄ‡∏•‡πá‡∏Å | ‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£‡πÉ‡∏´‡∏ç‡πà | Cloud-native |\n",
    "| **‡∏Ç‡πâ‡∏≠‡∏î‡∏µ** | Simple, ‡πÄ‡∏£‡πá‡∏ß | Queue management, ‡πÅ‡∏ä‡∏£‡πå resource | Auto-scaling, Isolate |\n",
    "| **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á** | Spark Standalone | AWS EMR, CDH | GKE, EKS |\n",
    "\n",
    "> üí° **‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏ô‡∏µ‡πâ** ‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ `local[*]` ‡∏ã‡∏∂‡πà‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á \"‡∏£‡∏±‡∏ô‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÉ‡∏ä‡πâ‡∏ó‡∏∏‡∏Å CPU core\" ‚Äî ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell_13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏î‡∏π‡∏ß‡πà‡∏≤‡πÄ‡∏£‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏ä‡πâ Cluster Manager ‡πÅ‡∏ö‡∏ö‡πÑ‡∏´‡∏ô\n",
    "print(f\"üè¢ Master URL: {spark.sparkContext.master}\")\n",
    "print()\n",
    "print(\"üìù ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á Master URL:\")\n",
    "print(\"  local     = ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß, 1 thread\")\n",
    "print(\"  local[*]  = ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß, ‡πÉ‡∏ä‡πâ‡∏ó‡∏∏‡∏Å core\")\n",
    "print(\"  local[4]  = ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß, 4 threads\")\n",
    "print(\"  yarn      = ‡πÉ‡∏ä‡πâ YARN ‡∏ö‡∏ô Hadoop cluster\")\n",
    "print(\"  k8s://... = ‡πÉ‡∏ä‡πâ Kubernetes cluster\")\n",
    "print(\"  spark://  = ‡πÉ‡∏ä‡πâ Standalone cluster\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell_14",
   "metadata": {},
   "source": [
    "# 5. ‚è≥ Lazy Evaluation (‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å)\n",
    "\n",
    "## ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á Spark\n",
    "\n",
    "> **Spark ‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡∏ô‡∏ó‡∏µ!** Spark ‡∏à‡∏∞ \"‡∏à‡∏î‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å\" ‡∏ß‡πà‡∏≤‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏∞‡πÑ‡∏£ ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢‡∏ó‡∏≥‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏£‡∏¥‡∏á ‡πÜ\n",
    "\n",
    "### ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö\n",
    "\n",
    "| | Pandas (Eager) | Spark (Lazy) |\n",
    "|---|---|---|\n",
    "| **‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á** | ‡∏ó‡∏≥‡∏ó‡∏±‡∏ô‡∏ó‡∏µ | ‡∏à‡∏î‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô (‡∏™‡∏£‡πâ‡∏≤‡∏á Plan) |\n",
    "| **‡∏Ç‡πâ‡∏≠‡∏î‡∏µ** | ‡πÄ‡∏´‡πá‡∏ô‡∏ú‡∏•‡πÄ‡∏•‡∏¢ | ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ú‡∏ô‡πÉ‡∏´‡πâ‡πÄ‡∏£‡πá‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏≥ |\n",
    "| **‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢** | ‡πÑ‡∏°‡πà optimize ‡∏Ç‡πâ‡∏≤‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô | ‡∏ï‡πâ‡∏≠‡∏á trigger ‡∏î‡πâ‡∏ß‡∏¢ Action |\n",
    "\n",
    "### Transformation vs Action\n",
    "\n",
    "#### üîπ Transformations (Lazy ‚Äî ‡∏à‡∏î‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ó‡∏≥)\n",
    "| ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á | ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà |\n",
    "|--------|--------|\n",
    "| `select()` | ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå |\n",
    "| `filter()` / `where()` | ‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏ñ‡∏ß |\n",
    "| `groupBy()` | ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏° |\n",
    "| `join()` | ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡∏≤‡∏£‡∏≤‡∏á |\n",
    "| `withColumn()` | ‡πÄ‡∏û‡∏¥‡πà‡∏°/‡πÅ‡∏Å‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå |\n",
    "| `orderBy()` | ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö |\n",
    "\n",
    "#### üî∏ Actions (‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏∞‡∏ï‡∏∏‡πâ‡∏ô ‚Äî ‡∏™‡∏±‡πà‡∏á‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏à‡∏£‡∏¥‡∏á!)\n",
    "| ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á | ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà |\n",
    "|--------|--------|\n",
    "| `show()` | ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• |\n",
    "| `count()` | ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß |\n",
    "| `collect()` | ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏°‡∏≤‡∏ó‡∏µ‡πà Driver |\n",
    "| `write()` | ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á disk |\n",
    "| `take(n)` | ‡∏î‡∏∂‡∏á n ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"images/lazy_evaluation.png\" width=\"800\" alt=\"Lazy Evaluation: ‡∏à‡∏î‡∏≠‡∏≠‡∏£‡πå‡πÄ‡∏î‡∏≠‡∏£‡πå (Transformation) vs ‡πÄ‡∏™‡∏¥‡∏£‡πå‡∏ü‡∏≠‡∏≤‡∏´‡∏≤‡∏£ (Action)\">\n",
    "  <br><i>Lazy Evaluation: ‡∏à‡∏î‡∏≠‡∏≠‡∏£‡πå‡πÄ‡∏î‡∏≠‡∏£‡πå (Transformation) vs ‡πÄ‡∏™‡∏¥‡∏£‡πå‡∏ü‡∏≠‡∏≤‡∏´‡∏≤‡∏£ (Action)</i>\n",
    "</div>\n"
   ],
   "id": "img_lazy_evaluation"
  },
  {
   "cell_type": "markdown",
   "id": "cell_15",
   "metadata": {},
   "source": [
    "### üî¨ Lab: ‡∏û‡∏¥‡∏™‡∏π‡∏à‡∏ô‡πå Lazy Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell_16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á\n",
    "data = [(i, f\"name_{i}\", i * 100, \"A\" if i % 2 == 0 else \"B\")\n",
    "        for i in range(1, 10001)]\n",
    "df = spark.createDataFrame(data, [\"id\", \"name\", \"salary\", \"dept\"])\n",
    "\n",
    "print(f\"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏Ç‡∏ô‡∏≤‡∏î {df.count()} ‡πÅ‡∏ñ‡∏ß\")\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell_17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# ===== Transformation (Lazy) ‚Äî ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô! =====\n",
    "print(\"üîπ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô Transformation...\")\n",
    "t0 = time.time()\n",
    "\n",
    "df2 = df.select(\"id\", \"salary\", \"dept\")      # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå\n",
    "df3 = df2.filter(df2[\"salary\"] > 500)         # ‡∏Å‡∏£‡∏≠‡∏á\n",
    "df4 = df3.groupBy(\"dept\").count()             # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"‚è±Ô∏è ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ (Transformation): {t1-t0:.4f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\")\n",
    "print(\"üí° ‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï: ‡πÄ‡∏£‡πá‡∏ß‡∏°‡∏≤‡∏Å ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ Spark ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏•‡∏¢!\")\n",
    "\n",
    "# ===== Action (Trigger!) ‚Äî ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ Spark ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á! =====\n",
    "print(\"\\nüî∏ ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Action (.show()) ‚Äî Spark ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô!\")\n",
    "t2 = time.time()\n",
    "\n",
    "df4.show()\n",
    "\n",
    "t3 = time.time()\n",
    "print(f\"‚è±Ô∏è ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ (Action): {t3-t2:.4f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\")\n",
    "print(\"üí° ‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï: ‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ Spark ‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥ Transformation ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell_18",
   "metadata": {},
   "source": [
    "### ‚úèÔ∏è ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏ó‡∏µ‡πà 2: Transformation vs Action\n",
    "\n",
    "**‡πÇ‡∏à‡∏ó‡∏¢‡πå:** ‡∏à‡∏≤‡∏Å‡πÇ‡∏Ñ‡πâ‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á ‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÑ‡∏´‡∏ô‡πÄ‡∏õ‡πá‡∏ô Transformation (T) ‡∏´‡∏£‡∏∑‡∏≠ Action (A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell_19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏ó‡∏µ‡πà 2: ‡πÄ‡∏ï‡∏¥‡∏° T (Transformation) ‡∏´‡∏£‡∏∑‡∏≠ A (Action)\n",
    "\n",
    "# ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà 1: df.select(\"name\", \"salary\")      ‚Üí  ________\n",
    "# ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà 2: df.filter(df[\"salary\"] > 1000)    ‚Üí  ________\n",
    "# ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà 3: df.count()                        ‚Üí  ________\n",
    "# ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà 4: df.groupBy(\"dept\").avg(\"salary\")  ‚Üí  ________\n",
    "# ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà 5: df.show(10)                       ‚Üí  ________\n",
    "# ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà 6: df.orderBy(\"salary\")              ‚Üí  ________\n",
    "# ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà 7: df.collect()                      ‚Üí  ________\n",
    "# ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà 8: df.withColumn(\"bonus\", df[\"salary\"] * 0.1)  ‚Üí  ________\n",
    "\n",
    "answers = {\n",
    "    1: \"________\",\n",
    "    2: \"________\",\n",
    "    3: \"________\",\n",
    "    4: \"________\",\n",
    "    5: \"________\",\n",
    "    6: \"________\",\n",
    "    7: \"________\",\n",
    "    8: \"________\",\n",
    "}\n",
    "\n",
    "for k, v in answers.items():\n",
    "    print(f\"‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell_20",
   "metadata": {},
   "source": [
    "# 6. üìä DAG (Directed Acyclic Graph)\n",
    "\n",
    "## DAG ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?\n",
    "\n",
    "DAG ‡∏Ñ‡∏∑‡∏≠ **‡∏Å‡∏£‡∏≤‡∏ü** ‡πÅ‡∏™‡∏î‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á Spark ‡πÇ‡∏î‡∏¢:\n",
    "- **Directed** = ‡∏°‡∏µ‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á (‡∏ó‡∏≥‡∏à‡∏≤‡∏Å‡∏ã‡πâ‡∏≤‡∏¢‡πÑ‡∏õ‡∏Ç‡∏ß‡∏≤)\n",
    "- **Acyclic** = ‡πÑ‡∏°‡πà‡∏ß‡∏ô‡∏ã‡πâ‡∏≥ (‡πÑ‡∏°‡πà‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏ó‡∏≥‡∏ã‡πâ‡∏≥)\n",
    "- **Graph** = ‡πÅ‡∏ú‡∏ô‡∏†‡∏≤‡∏û‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á\n",
    "\n",
    "```\n",
    "Read CSV ‚Üí Filter ‚Üí Select ‚Üí GroupBy ‚Üí [Shuffle] ‚Üí Aggregate ‚Üí Show\n",
    "  Stage 1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂  Stage 2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂\n",
    "```\n",
    "\n",
    "## ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ú‡∏ô\n",
    "\n",
    "1. **Logical Plan** ‚Äî ‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≤‡∏Å‡πÇ‡∏Ñ‡πâ‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô\n",
    "2. **Optimized Logical Plan** ‚Äî Catalyst Optimizer ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏´‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô\n",
    "3. **Physical Plan** ‚Äî ‡πÅ‡∏ú‡∏ô‡∏à‡∏£‡∏¥‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ó‡∏≥ (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏±‡∏•‡∏Å‡∏≠‡∏£‡∏¥‡∏ó‡∏∂‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏£‡πá‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)\n",
    "\n",
    "> üí° ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö: ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GPS ‚Äî ‡πÄ‡∏£‡∏≤‡∏ö‡∏≠‡∏Å‡∏à‡∏∏‡∏î‡∏´‡∏°‡∏≤‡∏¢ (Logical) ‚Üí GPS ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (Optimized) ‚Üí ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á (Physical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell_21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏î‡∏π Execution Plan ‡∏Ç‡∏≠‡∏á Spark\n",
    "df_plan = df.select(\"id\", \"salary\", \"dept\") \\\n",
    "            .filter(df[\"salary\"] > 500) \\\n",
    "            .groupBy(\"dept\") \\\n",
    "            .avg(\"salary\")\n",
    "\n",
    "print(\"üìã Execution Plan:\")\n",
    "print(\"=\" * 50)\n",
    "df_plan.explain(\"formatted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell_22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö: ‡∏î‡∏π‡πÅ‡∏ú‡∏ô‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î (extended)\n",
    "print(\"üìã Extended Plan (‡∏î‡∏π Logical ‚Üí Physical):\")\n",
    "print(\"=\" * 50)\n",
    "df_plan.explain(\"extended\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell_23",
   "metadata": {},
   "source": [
    "# 7. üîÄ Shuffle ‚Äî ‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á\n",
    "\n",
    "## Shuffle ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?\n",
    "\n",
    "Shuffle ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£ **‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á** (‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡πâ‡∏≤‡∏° partition) ‡πÄ‡∏°‡∏∑‡πà‡∏≠ Spark ‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà\n",
    "\n",
    "### ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà‡πÄ‡∏Å‡∏¥‡∏î Shuffle?\n",
    "\n",
    "| ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á | ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á Shuffle | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á |\n",
    "|--------|-----------------|---------|\n",
    "| `groupBy()` | ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏°‡∏≤‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà‡πÄ‡∏î‡∏µ‡∏¢‡∏ß | ‡∏ô‡∏±‡∏ö‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î |\n",
    "| `join()` | ‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å 2 ‡∏ï‡∏≤‡∏£‡∏≤‡∏á | JOIN orders ‡∏Å‡∏±‡∏ö customers |\n",
    "| `orderBy()` | ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î | ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏Ñ‡∏≤‡∏à‡∏≤‡∏Å‡∏°‡∏≤‡∏Å‡πÑ‡∏õ‡∏ô‡πâ‡∏≠‡∏¢ |\n",
    "| `distinct()` | ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ñ‡πà‡∏≤‡∏ã‡πâ‡∏≥‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î | ‡∏´‡∏≤‡∏à‡∏≥‡∏ô‡∏ß‡∏ô user ‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥ |\n",
    "\n",
    "### ‡∏ó‡∏≥‡πÑ‡∏° Shuffle ‡∏ñ‡∏∂‡∏á \"‡πÅ‡∏û‡∏á\"?\n",
    "\n",
    "> ‚ö†Ô∏è **Shuffle = ‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢ = ‡∏ä‡πâ‡∏≤!**\n",
    "\n",
    "```\n",
    "‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á 1: [A1, B2, A3]  ‚îÄ‚îÄ‚îÄ‚îÄ Network ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂  ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á 1: [A1, A3, A5] (‡∏Å‡∏•‡∏∏‡πà‡∏° A)\n",
    "‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á 2: [B4, A5, B6]  ‚îÄ‚îÄ‚îÄ‚îÄ Network ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂  ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á 2: [B2, B4, B6] (‡∏Å‡∏•‡∏∏‡πà‡∏° B)\n",
    "```\n",
    "\n",
    "- ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô disk ‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á (Spill)\n",
    "- ‡∏™‡πà‡∏á‡∏ú‡πà‡∏≤‡∏ô Network (‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤ RAM 1000 ‡πÄ‡∏ó‡πà‡∏≤)\n",
    "- ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏£‡∏ö‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"images/shuffle_concept.png\" width=\"800\" alt=\"Shuffle Concept: ‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡∏™‡∏µ‡∏•‡∏π‡∏Å‡∏ö‡∏≠‡∏•‡∏•‡∏á‡∏ñ‡∏±‡∏á‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á\">\n",
    "  <br><i>Shuffle Concept: ‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡∏™‡∏µ‡∏•‡∏π‡∏Å‡∏ö‡∏≠‡∏•‡∏•‡∏á‡∏ñ‡∏±‡∏á‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á</i>\n",
    "</div>\n"
   ],
   "id": "img_shuffle_concept"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell_24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏™‡∏≤‡∏ò‡∏¥‡∏ï‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á: ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ Shuffle vs ‡πÑ‡∏°‡πà‡∏°‡∏µ Shuffle\n",
    "import time\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏∂‡πâ‡∏ô\n",
    "big_data = [(i, f\"dept_{i % 50}\", i * 10.5) for i in range(100000)]\n",
    "big_df = spark.createDataFrame(big_data, [\"id\", \"department\", \"amount\"])\n",
    "\n",
    "# ===== ‡πÑ‡∏°‡πà‡∏°‡∏µ Shuffle (Narrow Transformation) =====\n",
    "t0 = time.time()\n",
    "result1 = big_df.filter(big_df[\"amount\"] > 5000).select(\"id\", \"amount\")\n",
    "result1.count()  # trigger action\n",
    "t1 = time.time()\n",
    "print(f\"üü¢ Filter + Select (‡πÑ‡∏°‡πà‡∏°‡∏µ Shuffle): {t1-t0:.3f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\")\n",
    "\n",
    "# ===== ‡∏°‡∏µ Shuffle (Wide Transformation) =====\n",
    "t2 = time.time()\n",
    "result2 = big_df.groupBy(\"department\").sum(\"amount\")\n",
    "result2.count()  # trigger action\n",
    "t3 = time.time()\n",
    "print(f\"üî¥ GroupBy + Sum (‡∏°‡∏µ Shuffle): {t3-t2:.3f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\")\n",
    "print(f\"\\nüí° ‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï: GroupBy ‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤ Filter ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ï‡πâ‡∏≠‡∏á Shuffle!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell_25",
   "metadata": {},
   "source": [
    "# 8. üß™ Lab: ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡∏î‡πâ‡∏ß‡∏¢ Spark\n",
    "\n",
    "### Step 1: ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell_26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Colab ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ crime.csv)\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "crime_types = [\"THEFT\", \"BATTERY\", \"ASSAULT\", \"BURGLARY\", \"NARCOTICS\",\n",
    "               \"ROBBERY\", \"MOTOR VEHICLE THEFT\", \"CRIMINAL DAMAGE\"]\n",
    "locations = [\"STREET\", \"APARTMENT\", \"RESIDENCE\", \"SIDEWALK\", \"PARKING LOT\"]\n",
    "\n",
    "crime_data = [\n",
    "    (i, random.choice(crime_types), random.choice(locations),\n",
    "     random.randint(2018, 2023), random.choice([True, False]))\n",
    "    for i in range(1, 50001)\n",
    "]\n",
    "\n",
    "df_crime = spark.createDataFrame(\n",
    "    crime_data,\n",
    "    [\"case_id\", \"primary_type\", \"location\", \"year\", \"arrest\"]\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {df_crime.count()} ‡πÅ‡∏ñ‡∏ß\")\n",
    "print(\"\\nüìä Schema:\")\n",
    "df_crime.printSchema()\n",
    "print(\"\\nüìã ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 5 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å:\")\n",
    "df_crime.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell_27",
   "metadata": {},
   "source": [
    "### Step 2: Transformation (Lazy) ‚Äî ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏≠‡∏∞‡πÑ‡∏£\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell_28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞ primary_type ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà null\n",
    "df_filtered = df_crime.select(\"primary_type\", \"year\", \"arrest\") \\\n",
    "                      .filter(df_crime[\"primary_type\"].isNotNull())\n",
    "\n",
    "print(\"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Transformation ‡πÄ‡∏™‡∏£‡πá‡∏à (‡πÅ‡∏ï‡πà Spark ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô!)\")\n",
    "print(f\"Type ‡∏Ç‡∏≠‡∏á df_filtered: {type(df_filtered)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell_29",
   "metadata": {},
   "source": [
    "### Step 3: Action ‚Äî ‡∏™‡∏±‡πà‡∏á‡πÉ‡∏´‡πâ Spark ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell_30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action: ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß (Spark ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á!)\n",
    "count_result = df_filtered.count()\n",
    "print(f\"üìä ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏≤‡∏ä‡∏ç‡∏≤‡∏Å‡∏£‡∏£‡∏°‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß: {count_result:,} ‡πÅ‡∏ñ‡∏ß\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell_31",
   "metadata": {},
   "source": [
    "### Step 4: ‡∏î‡∏π Execution Plan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell_32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏î‡∏π Plan ‡∏ß‡πà‡∏≤ Spark ‡∏à‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á\n",
    "print(\"üìã Execution Plan:\")\n",
    "df_filtered.explain(\"formatted\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell_33",
   "metadata": {},
   "source": [
    "# 9. üíæ Cache ‚Äî ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô RAM ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏ã‡πâ‡∏≥\n",
    "\n",
    "## ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ Cache?\n",
    "\n",
    "‡πÉ‡∏ä‡πâ `cache()` ‡πÄ‡∏°‡∏∑‡πà‡∏≠ **DataFrame ‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ‡∏ã‡πâ‡∏≥‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏£‡∏±‡πâ‡∏á**\n",
    "\n",
    "```\n",
    "‡πÑ‡∏°‡πà cache: Read ‚Üí Filter ‚Üí Count (‡∏≠‡πà‡∏≤‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á!)\n",
    "           Read ‚Üí Filter ‚Üí Show  (‡∏≠‡πà‡∏≤‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å!)\n",
    "           \n",
    "cache:     Read ‚Üí Filter ‚Üí [Cache ‡πÉ‡∏ô RAM]\n",
    "                              ‚îú‚îÄ‚Üí Count (‡∏≠‡πà‡∏≤‡∏ô‡∏à‡∏≤‡∏Å RAM!)\n",
    "                              ‚îî‚îÄ‚Üí Show  (‡∏≠‡πà‡∏≤‡∏ô‡∏à‡∏≤‡∏Å RAM!)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell_34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ã‡πâ‡∏≥\n",
    "df_analysis = df_crime.filter(df_crime[\"year\"] >= 2020)\n",
    "\n",
    "# ===== ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ Cache =====\n",
    "print(\"üî¥ ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ Cache:\")\n",
    "t0 = time.time()\n",
    "df_analysis.count()\n",
    "df_analysis.groupBy(\"primary_type\").count().show(5, truncate=False)\n",
    "t1 = time.time()\n",
    "print(f\"‚è±Ô∏è ‡πÄ‡∏ß‡∏•‡∏≤: {t1-t0:.3f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\\n\")\n",
    "\n",
    "# ===== ‡πÉ‡∏ä‡πâ Cache =====\n",
    "print(\"üü¢ ‡πÉ‡∏ä‡πâ Cache:\")\n",
    "df_analysis.cache()  # ‡∏ö‡∏≠‡∏Å Spark ‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô RAM\n",
    "\n",
    "t2 = time.time()\n",
    "df_analysis.count()  # ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å: ‡∏≠‡πà‡∏≤‡∏ô‡∏à‡∏≤‡∏Å source + ‡πÄ‡∏Å‡πá‡∏ö cache\n",
    "df_analysis.groupBy(\"primary_type\").count().show(5, truncate=False)\n",
    "t3 = time.time()\n",
    "print(f\"‚è±Ô∏è ‡πÄ‡∏ß‡∏•‡∏≤: {t3-t2:.3f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\")\n",
    "\n",
    "# ‡∏≠‡∏¢‡πà‡∏≤‡∏•‡∏∑‡∏° unpersist ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡πÅ‡∏•‡πâ‡∏ß!\n",
    "df_analysis.unpersist()\n",
    "print(\"\\nüóëÔ∏è Unpersist cache ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢ (‡∏Ñ‡∏∑‡∏ô RAM)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell_35",
   "metadata": {},
   "source": [
    "# 10. ‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢ (Common Pitfalls)\n",
    "\n",
    "| ‚ùå ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡∏ó‡∏≥ | üí• ‡∏ú‡∏•‡πÄ‡∏™‡∏µ‡∏¢ | ‚úÖ ‡∏ó‡∏≥‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡πÅ‡∏ó‡∏ô |\n",
    "|---|---|---|\n",
    "| `df.collect()` ‡∏ö‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏ç‡πà | Driver crash (‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡πÄ‡∏ï‡πá‡∏°) | ‡πÉ‡∏ä‡πâ `df.show()` ‡∏´‡∏£‡∏∑‡∏≠ `df.take(10)` |\n",
    "| JOIN ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÉ‡∏´‡∏ç‡πà 2 ‡∏ï‡∏≤‡∏£‡∏≤‡∏á ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà filter ‡∏Å‡πà‡∏≠‡∏ô | Shuffle ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏´‡∏≤‡∏®‡∏≤‡∏• | Filter ‡∏Å‡πà‡∏≠‡∏ô JOIN ‡πÄ‡∏™‡∏°‡∏≠ |\n",
    "| `inferSchema=True` ‡∏ö‡∏ô CSV ‡πÉ‡∏´‡∏ç‡πà | Spark ‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡πà‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏î‡∏≤ type | ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Schema ‡πÄ‡∏≠‡∏á |\n",
    "| Partition ‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ (‡πÄ‡∏ä‡πà‡∏ô 10,000) | Overhead ‡∏à‡∏≤‡∏Å scheduling | ‡πÉ‡∏ä‡πâ `coalesce()` ‡∏•‡∏î partition |\n",
    "| Partition ‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ (‡πÄ‡∏ä‡πà‡∏ô 1) | ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏à‡∏≤‡∏Å parallelism | ‡πÉ‡∏ä‡πâ `repartition()` ‡πÄ‡∏û‡∏¥‡πà‡∏° |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell_36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Schema ‡πÄ‡∏≠‡∏á (‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤ inferSchema)\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, BooleanType\n",
    "\n",
    "# ‚ùå ‡πÅ‡∏ö‡∏ö‡∏ä‡πâ‡∏≤ (inferSchema)\n",
    "# df = spark.read.csv(\"big_file.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# ‚úÖ ‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡πá‡∏ß (‡∏Å‡∏≥‡∏´‡∏ô‡∏î Schema ‡πÄ‡∏≠‡∏á)\n",
    "schema = StructType([\n",
    "    StructField(\"case_id\", IntegerType(), False),\n",
    "    StructField(\"primary_type\", StringType(), True),\n",
    "    StructField(\"location\", StringType(), True),\n",
    "    StructField(\"year\", IntegerType(), True),\n",
    "    StructField(\"arrest\", BooleanType(), True),\n",
    "])\n",
    "print(\"‚úÖ Schema ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏≠‡∏á:\")\n",
    "print(schema)\n",
    "print(\"\\nüí° ‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î Schema ‡πÄ‡∏≠‡∏á ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ Spark ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πÅ‡∏Å‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏î‡∏≤ type\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell_37",
   "metadata": {},
   "source": [
    "# 11. üìù ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏£‡∏ß‡∏° (Comprehensive Exercises)\n",
    "\n",
    "### ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏ó‡∏µ‡πà 3: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏ç‡∏≤‡∏Å‡∏£‡∏£‡∏°‡∏î‡πâ‡∏ß‡∏¢ Spark\n",
    "\n",
    "**‡πÇ‡∏à‡∏ó‡∏¢‡πå:** ‡πÉ‡∏ä‡πâ `df_crime` ‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß ‡∏ó‡∏≥‡∏ï‡∏≤‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell_38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏ó‡∏µ‡πà 3.1: ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏≤‡∏ä‡∏ç‡∏≤‡∏Å‡∏£‡∏£‡∏°‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó (primary_type)\n",
    "# ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏°‡∏≤‡∏Å‡πÑ‡∏õ‡∏ô‡πâ‡∏≠‡∏¢ ‡πÅ‡∏™‡∏î‡∏á 5 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å\n",
    "# TODO: ‡πÄ‡∏ï‡∏¥‡∏°‡πÇ‡∏Ñ‡πâ‡∏î\n",
    "\n",
    "result_3_1 = df_crime.groupBy(________) \\\n",
    "                     .count() \\\n",
    "                     .orderBy(________) \\\n",
    "                     .limit(5)\n",
    "\n",
    "result_3_1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell_39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏ó‡∏µ‡πà 3.2: ‡∏´‡∏≤‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Å‡∏∏‡∏° (arrest rate) ‡∏ï‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏≠‡∏≤‡∏ä‡∏ç‡∏≤‡∏Å‡∏£‡∏£‡∏°\n",
    "# Hint: ‡πÉ‡∏ä‡πâ avg(\"arrest\") ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ True=1, False=0\n",
    "# TODO: ‡πÄ‡∏ï‡∏¥‡∏°‡πÇ‡∏Ñ‡πâ‡∏î\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "result_3_2 = df_crime.groupBy(________) \\\n",
    "                     .agg(\n",
    "                         F.count(\"*\").alias(\"total_cases\"),\n",
    "                         F.________(________).alias(\"arrest_rate\")\n",
    "                     ) \\\n",
    "                     .orderBy(F.col(\"arrest_rate\").desc())\n",
    "\n",
    "result_3_2.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell_40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏ó‡∏µ‡πà 3.3: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏£‡∏≤‡∏¢‡∏õ‡∏µ\n",
    "# ‡∏´‡∏≤‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏≤‡∏ä‡∏ç‡∏≤‡∏Å‡∏£‡∏£‡∏°‡∏ï‡πà‡∏≠‡∏õ‡∏µ ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏õ‡∏µ\n",
    "# TODO: ‡πÄ‡∏ï‡∏¥‡∏°‡πÇ‡∏Ñ‡πâ‡∏î\n",
    "\n",
    "result_3_3 = df_crime.groupBy(________) \\\n",
    "                     .________ \\\n",
    "                     .orderBy(________)\n",
    "\n",
    "result_3_3.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell_41",
   "metadata": {},
   "source": [
    "### ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏ó‡∏µ‡πà 4: ‡∏î‡∏π Execution Plan\n",
    "\n",
    "**‡πÇ‡∏à‡∏ó‡∏¢‡πå:** ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô query ‡∏ó‡∏µ‡πà‡∏°‡∏µ Shuffle ‡πÅ‡∏•‡∏∞‡∏î‡∏π plan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell_42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏ó‡∏µ‡πà 4: ‡∏™‡∏£‡πâ‡∏≤‡∏á query ‡πÅ‡∏•‡πâ‡∏ß‡∏î‡∏π plan\n",
    "# TODO: ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô query ‡∏ó‡∏µ‡πà‡∏ó‡∏≥ 3 ‡∏≠‡∏¢‡πà‡∏≤‡∏á:\n",
    "# 1) Filter ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏õ‡∏µ 2020 ‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ\n",
    "# 2) GroupBy ‡∏ï‡∏≤‡∏° primary_type\n",
    "# 3) ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô + ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏°‡∏≤‡∏Å‡πÑ‡∏õ‡∏ô‡πâ‡∏≠‡∏¢\n",
    "\n",
    "my_query = df_crime \\\n",
    "    .________(________) \\\n",
    "    .________(________) \\\n",
    "    .________ \\\n",
    "    .orderBy(F.col(\"count\").desc())\n",
    "\n",
    "# ‡∏î‡∏π plan (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ)\n",
    "print(\"üìã Execution Plan ‡∏Ç‡∏≠‡∏á query ‡∏Ñ‡∏∏‡∏ì:\")\n",
    "my_query.explain(\"formatted\")\n",
    "print(\"\\nüìä ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:\")\n",
    "my_query.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell_43",
   "metadata": {},
   "source": [
    "### ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏ó‡∏µ‡πà 5: Cache Performance\n",
    "\n",
    "**‡πÇ‡∏à‡∏ó‡∏¢‡πå:** ‡∏û‡∏¥‡∏™‡∏π‡∏à‡∏ô‡πå‡∏ß‡πà‡∏≤ Cache ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô‡∏à‡∏£‡∏¥‡∏á\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell_44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏ó‡∏µ‡πà 5: ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Cache vs ‡πÑ‡∏°‡πà Cache\n",
    "import time\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô\n",
    "df_complex = df_crime.filter(df_crime[\"year\"] >= 2020) \\\n",
    "                     .withColumn(\"case_category\",\n",
    "                         F.when(F.col(\"arrest\") == True, \"ARRESTED\")\n",
    "                          .otherwise(\"NOT_ARRESTED\"))\n",
    "\n",
    "# TODO: ‡πÄ‡∏ï‡∏¥‡∏°‡πÇ‡∏Ñ‡πâ‡∏î\n",
    "\n",
    "# 1) ‡∏ß‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤ ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ cache (‡∏£‡∏±‡∏ô count + groupBy 2 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á)\n",
    "t0 = time.time()\n",
    "count1 = df_complex.________  # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô\n",
    "group1 = df_complex.groupBy(\"case_category\").count().________  # collect ‡∏ú‡∏•\n",
    "t1 = time.time()\n",
    "no_cache_time = t1 - t0\n",
    "\n",
    "# 2) Cache ‡πÅ‡∏•‡πâ‡∏ß‡∏ß‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏´‡∏°‡πà\n",
    "df_complex.________  # cache\n",
    "t2 = time.time()\n",
    "count2 = df_complex.________  # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô\n",
    "group2 = df_complex.groupBy(\"case_category\").count().________  # collect ‡∏ú‡∏•\n",
    "t3 = time.time()\n",
    "with_cache_time = t3 - t2\n",
    "\n",
    "print(f\"üî¥ ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ Cache: {no_cache_time:.3f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\")\n",
    "print(f\"üü¢ ‡πÉ‡∏ä‡πâ Cache: {with_cache_time:.3f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\")\n",
    "\n",
    "# ‡∏≠‡∏¢‡πà‡∏≤‡∏•‡∏∑‡∏° unpersist!\n",
    "df_complex.unpersist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell_45",
   "metadata": {},
   "source": [
    "# 12. üìå ‡∏™‡∏£‡∏∏‡∏õ (Summary)\n",
    "\n",
    "## ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ\n",
    "\n",
    "| ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ | ‡∏™‡∏£‡∏∏‡∏õ |\n",
    "|--------|------|\n",
    "| **‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÑ‡∏°‡πà‡∏û‡∏≠** | ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• > RAM/CPU ‚Üí ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Distributed Computing |\n",
    "| **Spark ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£** | Distributed Compute Engine (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà DB, ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà Storage) |\n",
    "| **Architecture** | Driver (‡∏™‡∏°‡∏≠‡∏á) + Executors (‡πÅ‡∏£‡∏á‡∏á‡∏≤‡∏ô) + Cluster Manager (‡∏ú‡∏π‡πâ‡∏à‡∏±‡∏î‡∏™‡∏£‡∏£) |\n",
    "| **Lazy Evaluation** | Transformation ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ú‡∏ô, Action ‡∏™‡∏±‡πà‡∏á‡∏ó‡∏≥ ‚Üí ‡∏ä‡πà‡∏ß‡∏¢ optimize |\n",
    "| **DAG** | ‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏™‡∏î‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô ‚Üí Catalyst Optimizer ‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏£‡πá‡∏ß |\n",
    "| **Shuffle** | ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á ‚Üí ‡∏ä‡πâ‡∏≤ ‡πÅ‡∏û‡∏á ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ß‡∏±‡∏á |\n",
    "| **Cache** | ‡πÄ‡∏Å‡πá‡∏ö DataFrame ‡πÉ‡∏ô RAM ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏ã‡πâ‡∏≥ ‚Üí ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤ |\n",
    "| **explain()** | ‡∏î‡∏π‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô ‚Üí ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ß‡πà‡∏≤ Spark ‡∏à‡∏∞‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£ |\n",
    "\n",
    "## üîÆ ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå‡∏´‡∏ô‡πâ‡∏≤: Data Pipeline\n",
    "\n",
    "> ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå‡∏ó‡∏µ‡πà 5: ‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Data Pipeline)  \n",
    "> ingest ‚Üí clean ‚Üí transform ‚Üí store ‚Üí analyze\n",
    "\n",
    "---\n",
    "\n",
    "## üìö ‡πÅ‡∏´‡∏•‡πà‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°\n",
    "\n",
    "- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)\n",
    "- [Spark: The Definitive Guide](https://www.oreilly.com/library/view/spark-the-definitive/9781491912201/)\n",
    "- [PySpark API Reference](https://spark.apache.org/docs/latest/api/python/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell_46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏õ‡∏¥‡∏î Spark Session\n",
    "spark.stop()\n",
    "print(\"‚úÖ ‡∏Ñ‡∏≤‡∏ö‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏ö‡πÅ‡∏•‡πâ‡∏ß! ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå‡∏´‡∏ô‡πâ‡∏≤: Data Pipeline üöÄ\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}